import sys
import os
import torch
import torchvision
import numpy as np
import pydicom
import glob
from torch.utils.data import DataLoader, random_split, Dataset
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, Callback
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning import Trainer
import torchvision.transforms.functional as F
from torchvision import transforms

# --- è·¯å¾„è®¾ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from src.core.reconstruction import SRTrainer


# ==========================================
# ä¼˜åŒ–ç‰ˆ Dataset: å…¨å†…å­˜ç¼“å­˜ (RAM Cache)
# ==========================================
class CTInMemoryDataset(Dataset):
    def __init__(self, data_dir, phase='train', crop_size=128, scale_factor=4):
        super().__init__()
        self.phase = phase
        self.crop_size = crop_size
        self.scale_factor = scale_factor

        # 1. æœé›†æ–‡ä»¶è·¯å¾„
        dcm_files = sorted(glob.glob(os.path.join(data_dir, "**/*.dcm"), recursive=True))
        if len(dcm_files) == 0:
            raise ValueError(f"No .dcm files found in {data_dir}")

        print(f"[{phase}] æ­£åœ¨å°† {len(dcm_files)} å¼  DICOM é¢„åŠ è½½åˆ°å†…å­˜ (æé€Ÿæ¨¡å¼)...")

        self.data_cache = []

        # 2. ä¸€æ¬¡æ€§è¯»å–æ‰€æœ‰æ•°æ®åˆ°å†…å­˜
        for dcm_path in dcm_files:
            try:
                ds = pydicom.dcmread(dcm_path)
                try:
                    ds.decompress()
                except:
                    pass

                if hasattr(ds, 'pixel_array'):
                    slope = getattr(ds, 'RescaleSlope', 1.0)
                    intercept = getattr(ds, 'RescaleIntercept', 0.0)
                    img_hu = ds.pixel_array.astype(np.float32) * slope + intercept

                    # å½’ä¸€åŒ– [-1000, 2000] -> [0, 1]
                    img_norm = np.clip(img_hu, -1000, 2000)
                    img_norm = (img_norm + 1000) / 3000.0

                    # è½¬ä¸º Tensor å¹¶ä¿å­˜åˆ°åˆ—è¡¨
                    # [1, H, W]
                    tensor = torch.from_numpy(img_norm).unsqueeze(0).float()
                    self.data_cache.append(tensor)
            except Exception as e:
                pass  # è·³è¿‡åæ–‡ä»¶

        print(f"[{phase}] é¢„åŠ è½½å®Œæˆï¼æœ‰æ•ˆå›¾ç‰‡: {len(self.data_cache)} å¼ ")

    def __len__(self):
        return len(self.data_cache)

    def __getitem__(self, index):
        # ç›´æ¥ä»å†…å­˜æ‹¿ï¼Œä¸éœ€è¦ IOï¼Œé€Ÿåº¦æå¿«
        hr_tensor = self.data_cache[index]

        # å°ºå¯¸æ£€æŸ¥
        if hr_tensor.shape[1] < self.crop_size or hr_tensor.shape[2] < self.crop_size:
            # éšæœºæ¢ä¸€å¼ 
            return self.__getitem__(np.random.randint(0, len(self.data_cache)))

        # è®­ç»ƒå¢å¼º
        if self.phase == 'train':
            i, j, h, w = transforms.RandomCrop.get_params(
                hr_tensor, output_size=(self.crop_size, self.crop_size)
            )
            hr_tensor = F.crop(hr_tensor, i, j, h, w)
            if torch.rand(1) < 0.5: hr_tensor = F.hflip(hr_tensor)
            if torch.rand(1) < 0.5: hr_tensor = F.vflip(hr_tensor)

        # ç”Ÿæˆ LR
        lr_h = hr_tensor.shape[1] // self.scale_factor
        lr_w = hr_tensor.shape[2] // self.scale_factor

        lr_tensor = torch.nn.functional.interpolate(
            hr_tensor.unsqueeze(0),
            size=(lr_h, lr_w),
            mode='bicubic',
            align_corners=False
        ).squeeze(0)

        return {"lr": lr_tensor, "hr": hr_tensor}


# ==========================================
# å›¾ç‰‡å¯è§†åŒ–å›è°ƒ
# ==========================================
class ImageLogger(Callback):
    def __init__(self, num_samples=4):
        super().__init__()
        self.num_samples = num_samples

    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):
        if batch_idx == 0:
            try:
                lr = batch["lr"][:self.num_samples]
                hr = batch["hr"][:self.num_samples]
                with torch.no_grad():
                    sr = pl_module(lr)
                lr_upscaled = torch.nn.functional.interpolate(lr, size=hr.shape[2:], mode='nearest')

                grid_lr = torchvision.utils.make_grid(lr_upscaled, nrow=4, normalize=True)
                grid_sr = torchvision.utils.make_grid(sr, nrow=4, normalize=True)
                grid_hr = torchvision.utils.make_grid(hr, nrow=4, normalize=True)

                trainer.logger.experiment.add_image('1_Input_LowRes', grid_lr, trainer.global_step)
                trainer.logger.experiment.add_image('2_Output_SuperRes', grid_sr, trainer.global_step)
                trainer.logger.experiment.add_image('3_GroundTruth_HighRes', grid_hr, trainer.global_step)
            except Exception:
                pass


def main():
    # ================= æé€Ÿç‰ˆé…ç½® =================
    DATA_DIR = os.path.join(project_root, "data", "raw")

    # ä¼˜åŒ– 1: å¤§å¹…å¢åŠ  Batch Size (4060 æ˜¾å­˜å¤Ÿç”¨)
    BATCH_SIZE = 64

    # ä¼˜åŒ– 2: é€‚å½“çš„ Workers (Windowsä¸‹å»ºè®® 2-4ï¼Œé…åˆ persistent_workers)
    NUM_WORKERS = 4

    MAX_EPOCHS = 300  # è·‘å¾—å¿«äº†ï¼Œå¯ä»¥å¤šè·‘å‡ è½®
    LR = 1e-4
    CROP_SIZE = 128
    SCALE_FACTOR = 4
    # ===========================================

    pl.seed_everything(42)

    # 1. å‡†å¤‡æ•°æ® (ä½¿ç”¨å†…å­˜ Dataset)
    print(f"ğŸš€ åˆå§‹åŒ–æé€Ÿæ•°æ®åŠ è½½å™¨...")
    full_dataset = CTInMemoryDataset(DATA_DIR, phase='train', crop_size=CROP_SIZE, scale_factor=SCALE_FACTOR)

    train_size = int(0.9 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    # ä¼˜åŒ– 3: persistent_workers=True
    # è¿™è®© Windows ä¸ä¼šåœ¨æ¯ä¸ª Epoch ç»“æŸæ—¶æ€æ­»è¿›ç¨‹ï¼Œæå¤§å‡å°‘ CPU å¼€é”€
    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=NUM_WORKERS,
        pin_memory=True,
        persistent_workers=True if NUM_WORKERS > 0 else False
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
        persistent_workers=True if NUM_WORKERS > 0 else False
    )

    model = SRTrainer(lr=LR)

    checkpoint_callback = ModelCheckpoint(
        dirpath=os.path.join(project_root, "checkpoints", "sr_model"),
        filename='srgan-{epoch:02d}-{val_loss:.5f}',
        save_top_k=3,
        monitor='val_loss',
        mode='min'
    )

    logger = TensorBoardLogger(os.path.join(project_root, "logs"), name="sr_experiment_fast")
    img_logger = ImageLogger(num_samples=4)

    # ä¼˜åŒ– 4: å¼€å¯ Benchmark (åŠ é€Ÿå·ç§¯å¯»æ‰¾ç®—æ³•)
    torch.backends.cudnn.benchmark = True
    torch.set_float32_matmul_precision('medium')

    trainer = Trainer(
        max_epochs=MAX_EPOCHS,
        accelerator="gpu",
        devices=1,
        logger=logger,
        callbacks=[checkpoint_callback, LearningRateMonitor(logging_interval='step'), img_logger],
        log_every_n_steps=5,
        check_val_every_n_epoch=1,

        # ä¼˜åŒ– 5: å¼€å¯æ··åˆç²¾åº¦ (16-mixed) -> RTX 4060 æé€Ÿç¥å™¨
        precision="16-mixed"
    )

    print("ğŸš€ å¼€å§‹è®­ç»ƒ (æé€Ÿç‰ˆ)...")
    print(f"Batch Size: {BATCH_SIZE} | Precision: 16-mixed | RAM Cache: ON")

    trainer.fit(model, train_loader, val_loader)


if __name__ == "__main__":
    main()